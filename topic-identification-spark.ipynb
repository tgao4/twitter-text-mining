{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "data = sc.textFile(\"Clean_Tweets1.txt\")\n",
    "documents = data.map(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['toyota',\n",
       "  'second',\n",
       "  'attempt',\n",
       "  'ship',\n",
       "  'prius',\n",
       "  'car',\n",
       "  'photovoltaic',\n",
       "  'roof',\n",
       "  'current',\n",
       "  'tech',\n",
       "  'still',\n",
       "  'far'],\n",
       " ['hydrogen', 'solution', 'energy', 'storage']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.types import StringType\n",
    "df2 = spark.createDataFrame(documents,ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|[toyota, second, ...|\n",
      "|[hydrogen, soluti...|\n",
      "|[new, solar, cell...|\n",
      "|[bosch, vision, a...|\n",
      "|[sun, hot, topic,...|\n",
      "|[see, divine, fem...|\n",
      "|          [well, do]|\n",
      "|[paint, road, gre...|\n",
      "|[bargain, solar, ...|\n",
      "|[crazy, solar, ec...|\n",
      "|[copy, consumer, ...|\n",
      "|[publish, medium,...|\n",
      "|[wind, solar, ene...|\n",
      "|[magnetic, fly, s...|\n",
      "|[high, cost, capi...|\n",
      "|[household, pay, ...|\n",
      "|[solar, power, tree]|\n",
      "|[benefit, locally...|\n",
      "|[tan, fan, ura, l...|\n",
      "|[solar, energy, e...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"value\", outputCol=\"rawFeatures\", vocabSize=1000, minDF=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = cv.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------+\n",
      "|value                                                                                             |rawFeatures                                                                 |\n",
      "+--------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------+\n",
      "|[toyota, second, attempt, ship, prius, car, photovoltaic, roof, current, tech, still, far]        |(1000,[101,196,306,319,550,714,886],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])          |\n",
      "|[hydrogen, solution, energy, storage]                                                             |(1000,[1,39,97],[1.0,1.0,1.0])                                              |\n",
      "|[new, solar, cell, capture, nearly, energy, solar, spectrum]                                      |(1000,[0,1,6,119,182,335,594],[2.0,1.0,1.0,1.0,1.0,1.0,1.0])                |\n",
      "|[bosch, vision, aim, reduce, emission, relative, value, add]                                      |(1000,[176,207,344,407,618,693],[1.0,1.0,1.0,1.0,1.0,1.0])                  |\n",
      "|[sun, hot, topic, salena, morrow, discuss, alaska, structural, engineer, support, solar, energy]  |(1000,[0,1,37,91,559,919],[1.0,1.0,1.0,1.0,1.0,1.0])                        |\n",
      "|[see, divine, feminine, energy, come]                                                             |(1000,[1,60,90,701],[1.0,1.0,1.0,1.0])                                      |\n",
      "|[well, do]                                                                                        |(1000,[241,429],[1.0,1.0])                                                  |\n",
      "|[paint, road, grey, waste, solar, energy, use, sun, benefit]                                      |(1000,[0,1,13,37,142,725],[1.0,1.0,1.0,1.0,1.0,1.0])                        |\n",
      "|[bargain, solar, energy, power, car, tire, wheel, light, via]                                     |(1000,[0,1,2,9,28,196],[1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|[crazy, solar, eclipse, throw, whole, energy, wild]                                               |(1000,[0,1,4,350,525,881],[1.0,1.0,1.0,1.0,1.0,1.0])                        |\n",
      "|[copy, consumer, urge, reduce, electricity, usage, unplug, electronics, mon, per, story]          |(1000,[43,176,242,493,615,747,794],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[publish, medium, post, check]                                                                    |(1000,[105,258,870],[1.0,1.0,1.0])                                          |\n",
      "|[wind, solar, energy]                                                                             |(1000,[0,1,3],[1.0,1.0,1.0])                                                |\n",
      "|[magnetic, fly, saucer, driven, solar, energy, cn, u]                                             |(1000,[0,1,10,432],[1.0,1.0,1.0,1.0])                                       |\n",
      "|[high, cost, capital, slow, decline, panel, price, threaten, profitability, solar, project, india]|(1000,[0,5,14,25,107,152,203,426,538],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[household, pay, solar, energy, report]                                                           |(1000,[0,1,98,135,231],[1.0,1.0,1.0,1.0,1.0])                               |\n",
      "|[solar, power, tree]                                                                              |(1000,[0,2],[1.0,1.0])                                                      |\n",
      "|[benefit, locally, own, renewable, energy, via]                                                   |(1000,[1,7,9,142],[1.0,1.0,1.0,1.0])                                        |\n",
      "|[tan, fan, ura, light, gex, option]                                                               |(1000,[28,905],[1.0,1.0])                                                   |\n",
      "|[solar, energy, even, work, night]                                                                |(1000,[0,1,79,84,302],[1.0,1.0,1.0,1.0,1.0])                                |\n",
      "+--------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(df2)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = model.vocabulary\n",
    "vocab_broadcast = sc.broadcast(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "#hashingTF = HashingTF(inputCol=\"value\", outputCol=\"rawFeatures\", numFeatures=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#featurizedData = hashingTF.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idfModel = idf.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rescaledData = idfModel.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(1000,[101,196,30...|\n",
      "|(1000,[1,39,97],[...|\n",
      "|(1000,[0,1,6,119,...|\n",
      "|(1000,[176,207,34...|\n",
      "|(1000,[0,1,37,91,...|\n",
      "|(1000,[1,60,90,70...|\n",
      "|(1000,[241,429],[...|\n",
      "|(1000,[0,1,13,37,...|\n",
      "|(1000,[0,1,2,9,28...|\n",
      "|(1000,[0,1,4,350,...|\n",
      "|(1000,[43,176,242...|\n",
      "|(1000,[105,258,87...|\n",
      "|(1000,[0,1,3],[0....|\n",
      "|(1000,[0,1,10,432...|\n",
      "|(1000,[0,5,14,25,...|\n",
      "|(1000,[0,1,98,135...|\n",
      "|(1000,[0,2],[0.37...|\n",
      "|(1000,[1,7,9,142]...|\n",
      "|(1000,[28,905],[3...|\n",
      "|(1000,[0,1,79,84,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LDA(k=10, seed=123, optimizer=\"em\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel= lda.fit(rescaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[78, 77, 111, 13,...|[0.01878740098879...|\n",
      "|    1|[27, 56, 144, 124...|[0.02234461353753...|\n",
      "|    2|[76, 4, 136, 34, ...|[0.01740265220412...|\n",
      "|    3|[145, 1, 159, 31,...|[0.01643813697646...|\n",
      "|    4|[2, 18, 101, 42, ...|[0.02556384629924...|\n",
      "|    5|[17, 28, 41, 2, 3...|[0.03401049878239...|\n",
      "|    6|[30, 66, 68, 67, ...|[0.02371864805385...|\n",
      "|    7|[57, 85, 40, 79, ...|[0.02531449653623...|\n",
      "|    8|[48, 6, 63, 105, ...|[0.03642119201522...|\n",
      "|    9|[12, 46, 110, 108...|[0.02669104210769...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldatopics = ldamodel.describeTopics()\n",
    "ldatopics.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_termID_to_Word(termIndices):\n",
    "    words = []\n",
    "    for termID in termIndices:\n",
    "        words.append(vocab_broadcast.value[termID])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "udf_map_termID_to_Word =UserDefinedFunction(map_termID_to_Word , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldatopics_mapped = ldatopics.withColumn(\"topic_desc\", udf_map_termID_to_Word(ldatopics.termIndices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|               value|         rawFeatures|            features|   topicDistribution|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|[toyota, second, ...|(1000,[101,196,30...|(1000,[101,196,30...|[0.06104347306875...|\n",
      "|[hydrogen, soluti...|(1000,[1,39,97],[...|(1000,[1,39,97],[...|[0.08994214994102...|\n",
      "|[new, solar, cell...|(1000,[0,1,6,119,...|(1000,[0,1,6,119,...|[0.07220296451517...|\n",
      "|[bosch, vision, a...|(1000,[176,207,34...|(1000,[176,207,34...|[0.10500829409018...|\n",
      "|[sun, hot, topic,...|(1000,[0,1,37,91,...|(1000,[0,1,37,91,...|[0.07961827877802...|\n",
      "|[see, divine, fem...|(1000,[1,60,90,70...|(1000,[1,60,90,70...|[0.09034843081697...|\n",
      "|          [well, do]|(1000,[241,429],[...|(1000,[241,429],[...|[0.08576108411485...|\n",
      "|[paint, road, gre...|(1000,[0,1,13,37,...|(1000,[0,1,13,37,...|[0.09852136300376...|\n",
      "|[bargain, solar, ...|(1000,[0,1,2,9,28...|(1000,[0,1,2,9,28...|[0.08448436700216...|\n",
      "|[crazy, solar, ec...|(1000,[0,1,4,350,...|(1000,[0,1,4,350,...|[0.10168230300491...|\n",
      "|[copy, consumer, ...|(1000,[43,176,242...|(1000,[43,176,242...|[0.09639057893776...|\n",
      "|[publish, medium,...|(1000,[105,258,87...|(1000,[105,258,87...|[0.09632763118110...|\n",
      "|[wind, solar, ene...|(1000,[0,1,3],[1....|(1000,[0,1,3],[0....|[0.10023514987425...|\n",
      "|[magnetic, fly, s...|(1000,[0,1,10,432...|(1000,[0,1,10,432...|[0.09071667471039...|\n",
      "|[high, cost, capi...|(1000,[0,5,14,25,...|(1000,[0,5,14,25,...|[0.08162043001642...|\n",
      "|[household, pay, ...|(1000,[0,1,98,135...|(1000,[0,1,98,135...|[0.08071409460280...|\n",
      "|[solar, power, tree]|(1000,[0,2],[1.0,...|(1000,[0,2],[0.37...|[0.09828366993924...|\n",
      "|[benefit, locally...|(1000,[1,7,9,142]...|(1000,[1,7,9,142]...|[0.09346213726327...|\n",
      "|[tan, fan, ura, l...|(1000,[28,905],[1...|(1000,[28,905],[3...|[0.08689833267841...|\n",
      "|[solar, energy, e...|(1000,[0,1,79,84,...|(1000,[0,1,79,84,...|[0.08964871776145...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldaResults = ldamodel.transform(rescaledData)\n",
    "ldaResults.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------+\n",
      "|topic|topic_desc                                                                  |\n",
      "+-----+----------------------------------------------------------------------------+\n",
      "|0    |[find, next, technology, use, home, bill, panel, eclipse, nuclear, energy]  |\n",
      "|1    |[thanks, daily, school, business, wall, big, australia, energy, make, clean]|\n",
      "|2    |[time, eclipse, europe, great, year, effort, instal, two, solar, energy]    |\n",
      "|3    |[move, energy, planet, news, use, right, solar, rise, new, plan]            |\n",
      "|4    |[power, plant, roof, battery, become, set, gas, wind, electricity, price]   |\n",
      "|5    |[save, light, money, power, wind, lead, program, americans, amount, live]   |\n",
      "|6    |[coal, farm, world, read, like, largest, produce, eclipse, moon, u]         |\n",
      "|7    |[water, tesla, first, even, city, country, company, year, storage, support] |\n",
      "|8    |[rt, new, fight, post, blog, interest, report, today, change, company]      |\n",
      "|9    |[could, provide, potential, fuel, pv, power, cell, drop, work, energy]      |\n",
      "+-----+----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldatopics_mapped.select('topic', 'topic_desc').show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
